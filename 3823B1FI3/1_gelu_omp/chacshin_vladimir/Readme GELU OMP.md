
# OpenMP GELU Implementation

## Общая информация

Реализация функции активации **GELU (Gaussian Error Linear Unit)** на C++ с использованием **OpenMP** и **AVX2-friendly циклов**. Основная цель — высокопроизводительное вычисление GELU для больших векторов на CPU.

**Тестовая система:**

- CPU: Intel Core i5-12500H (12 ядер: 4 P + 8 E)
    
- GPU: NVIDIA RTX 3060 Mobile (для справки, GPU не используется в этой реализации)
    
- ОС: Windows 11 Pro 24H2
    
- Компилятор: Intel C++ Compiler 2025

---

## Ключи оптимизации компилятора

Для сборки использовались следующие ключи Intel C++ Compiler:

```
-xHost -Qopt-zmm-usage=high -Qopt-report=3 -Qopt-report-phase=all -Qopt-report-file="report.txt" -xCORE-AVX2 -Qopenmp -Qimf-precision=low /fp:fast
```

- `-xHost` — компиляция под текущий CPU с максимальной поддержкой ISA
    
- `-Qopt-zmm-usage=high` — активирует более агрессивное использование ZMM/AVX регистров
    
- `-Qopt-report=3`, `-Qopt-report-phase=all`, `-Qopt-report-file="report.txt"` — создаёт подробный отчёт оптимизации
    
- `-xCORE-AVX2` — целевой набор инструкций AVX2
    
- `-Qopenmp` — включение OpenMP для параллельного выполнения
    
- `-Qimf-precision=low /fp:fast` — ускорение математических функций с небольшим допуском по точности

---

## Математическая основа

Для ускорения вычислений используется **аппроксимация GELU**, которая заменяет оригинальный `tanh` и `exp` на полиномиальную форму:

```cpp
float x0 = input[i + 0];
float t0 = 1.702f * x0;
float s0 = ((-0.004f * t0 + 0.197f) * t0 + 0.5f);
output[i + 0] = x0 * s0;
```

### Объяснение:

1. `t0 = 1.702 * x` — масштабирование входа для аппроксимации GELU.
    
2. `s0 = ((-0.004 * t0 + 0.197) * t0 + 0.5)` — полиномиальная аппроксимация функции `0.5 * (1 + tanh(...))`, заменяющая вычисления экспоненты и tanh.
    
3. `output[i] = x * s` — финальная формула GELU.

Такой подход **уменьшает задержку операций**, снижает зависимость от сложных математических функций (`exp`, `tanh`) и полностью раскрывает FMA-цепочки для AVX2.

---

## Параллельность и векторизация

- Используется **OpenMP** с фиксированным числом потоков `12` (для i5-12500H).
    
- Основной цикл **разворачивается на 8 элементов** для лучшей векторизации и совместимости с AVX2.
    
- Для повышения производительности используется **блочное выполнение**:

```cpp
const size_t block_size = 290000; // размер блока для кэша L2
#pragma omp parallel for schedule(static)
for (size_t b = 0; b < n; b += block_size) {
    size_t end = std::min(b + block_size, n);
    // внутренний цикл по 8 элементов с разворачиванием
}
```

- Блоки помогают держать данные в **кэше L2** и уменьшить задержки из-за обращений к DRAM.

---

## Подсчёт времени выполнения

Для измерения производительности выполнялось **40 повторов** и усреднение времени:

```cpp
long long sum_ms = 0;
for (int i = 0; i < 40; i++) {
    auto start = std::chrono::high_resolution_clock::now();
    output = GeluOMP(input);
    auto end = std::chrono::high_resolution_clock::now();
    auto duration_ms = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();
    sum_ms += duration_ms;
}

std::cout << "GELU computed for " << N << " elements in " << sum_ms / 40.0f << " ms.\n";
```

- **Лучший запуск:** 186 ms
    
- **Среднее:** около 194 ms

---

## Вывод

- Аппроксимация с полиномом обеспечивает **быструю обработку больших векторов**.
    
- OpenMP + развёрнутый цикл + блоки под L2 дают **эффективную параллельность и векторизацию**.
    
- Использование AVX2 FMA-инструкций (неявно через полином и компилятор) позволяет **максимально загрузить CPU**.
    
- На i5-12500H удалось достичь ~2× ускорения по сравнению с прямой реализацией с `tanh`/`exp`.
